\chapter{Introduction}
\label{chapter:intro}

Deep learning requires vast amounts of high quality data\cite{korakakis2018short}. Obtaining quality annotations from real-world data is a high-cost endeavor, and presents issues with data diversity and licensing\cite{asano2021pass}. To overcome these limitations, we advocate the use of synthetic data for deep learning vision tasks.

To this end, we combined data from open access GIS (Geographic Information System) services with procedural modeling techniques, to develop The Procedural Outdoors Scene Generator\footnote{\url{https://github.com/gabriel-v/the_procedural_outdoors}}, an open-source Python framework aimed at generating realistic synthetic video data of outdoor environments. We used this system to create a realistic scene with rail tracks, together with per-pixel annotation data. The resulting datasets are evaluated for usefulness in training a machine learning model for semantic segmentation of the tracks.

We discuss the general approach in Chapter \ref{chapter:approach}, implementation details in Chapter \ref{chapter:implementation}, and evaluate the benefits of using data generated from this system for a specific machine learning segmentation task in Chapter \ref{chapter:testing-and-evaluation}. Finally, a long-term plan is made in Chapter \ref{chapter:further-work} to extend the framework into a comprehensive ecosystem of freely licensed procedurally generated assets and scenes.

The next section explains the design considerations that were taken into account when deciding on the approach.

% ###############################################################
\section{Design Requirements}
\label{sec:design-requirements}


\begin{description}
    \item[Makes use of GIS data.] Publicly available Geographic Information Systems (GIS) distribute a variety of data, such as satellite imagery, altitude maps, and data on streets, highways, railroads, buildings and urban zoning areas. The framework includes a method to access and combine multiple data sources into a single 3D environment object containing the raw data for generating a scene.
    \item[Capable of procedural 3D modeling.] Specialized 3D artists can create and modify procedurally generated 3D assets, including their textures and shaders, independently of the research team which implements the simulation logic in Python. Procedural 3D modeling can also be used to create variations of existing static 3D objects and their texture and shader information.
    \item[Open.]  The framework must be based on open-source code, and enable the sharing, distribution and modification of both user code and procedurally generated 3D objects. The framework is based on the Kubric\cite{greff2021kubric} library, which uses the Blender 3D computer graphics software as  the rendering backend. Both these components are free and open-source, which makes it possible to analyze and modify any component, including the rendering engine.
    \item[Portable and Scalable.]  All components of the framework are easily deployable on cloud hardware. Rendering tasks can be parallelized by running multiple instances of the same parameter settings.
    \item[Interactive Rendering.] The framework must support tasks in which the machine learning algorithm needs to effect changes in the scene. An example of this would be an online reinforcement learning model learning to guide a drone over rail tracks: at each frame, the training algorithm decides of a movement, and the simulation must update its scene based on that movement.
\end{description}
